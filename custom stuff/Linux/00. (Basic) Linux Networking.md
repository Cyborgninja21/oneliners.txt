# (Basic) Linux Networking.md

## Table of Contents

- [History](#history)






```i
GENERAL NETWORKING
==================
(*) Query my external IP address: `curl -4 https://icanhazip.com`
(*) (SU) List processes that are actively using a port: `netstat -tulpn | grep LISTEN`

(*) List interfaces with detailed info: `ip a`
(*) List interfaces with brief network layer info: `ip -brief address`
(*) List interfaces with brief link layer info: `ip -brief link`
(*) Display the routing table: `ip route`
(*) Show neighbors (ARP table): `ip neighbour`
(*) Make an interface up/down: `ip link set interface up/down`
(*) Add/Delete an IP address to an interface: `ip addr add/del ip/mask dev interface`
(*) Add a default route: `ip route add default via ip dev interface`
(*) Show current network interface in use: `ip a | awk '/state UP/ {print $2}' | sed 's/.$//'`
(*) Extract all ip addresses from both ip and ifconfig commands output: `ip a | grep -oP '(?<=inet |addr:)(?:\d+\.){3}\d+'`
(*) Show your current network interface in use: `ip r show default | awk '{print $5}'`
(*) Automatically generate the ip/hostname entry for the /etc/hosts in the current system: `echo "$(ip addr show dev $(ip r | grep -oP 'default.*dev \K\S*') | grep -oP '(?<=inet )[^/]*(?=/)') $(hostname -f) $(hostname -s)"`



(*) Block all IPv4 addresses that has brute forcing our ssh server: `for idiots in "$(cat /var/log/auth.log|grep invalid| grep -oE '\b([0-9]{1,3}\.){3}[0-9]{1,3}\b')"; do iptables -A INPUT -s "$idiots" -j DROP; done`
(*) Watch how many tcp connections there are per state every two seconds: `watch -c "netstat -natp 2>/dev/null | tail -n +3 | awk '{print \$6}' | sort | uniq -c"`
(*) Watch how many tcp connections there are per state every two seconds: `watch -c "netstat -nt | awk 'FNR > 3 {print \$6}' | sort | uniq -c"`
(*) Watch TCP, UDP open ports in real time with socket summary.: `watch ss -stplu`
(*) Fast portscanner via xargs: `xargs -i -P 1200 nc -zvn {} 22 < textfile-with-hosts.txt`
(*) Check whether IPv6 is enabled: `printf "IPv6 is "; [ $(cat /proc/sys/net/ipv6/conf/all/disable_ipv6) -eq 0 ] && printf "enabled\n" || printf "disabled\n"`

(*) Capture SMTP / POP3 Email: `sudo tcpdump -nn -l port 25 | grep -i 'MAIL FROM\|RCPT TO'`
(*) Capture FTP Credentials and Commands: `sudo tcpdump -nn -v port ftp or ftp-data`
(*) Capture all plaintext passwords: `sudo tcpdump port http or port ftp or port smtp or port imap or port pop3 or port telnet -l -A | egrep -i -B5 'pass=|pwd=|log=|login=|user=|username=|pw=|passw=|passwd=|password=|pass:|user:|username:|password:|login:|pass |user '`
(*) Extract HTTP Passwords in POST Requests: `sudo tcpdump -s 0 -A -n -l | egrep -i "POST /|pwd=|passwd=|password=|Host:"`
(*) (Powershell) telnet in Windows: `Test-NetConnection -ComputerName example.com -Port 443`

(*) Display all TCP sockets: `ss -t -a`
(*) Display all TCP sockets with process SELinux security contexts: `ss -t -a -Z`
(*) Display all UDP sockets: `ss -u -a`
(*) Display all established ssh connections: `ss -o state established '( dport = :ssh or sport = :ssh )'`
(*) Find all local processes connected to X server: `ss -x src /tmp/.X11-unix/*`
(*) List all the tcp sockets in state FIN-WAIT-1 for our apache to network 193.233.7/24 and look at their timers.: `ss -o state fin-wait-1 '( sport = :http or sport = :https )' dst 193.233.7/24`
(*) List sockets in all states from all socket tables but TCP: `ss -a -A 'all,!tcp'`
(*) Find all clients connected to HTTP or HTTPS ports: `ss -o state established '( dport = :http or sport = :https )'`
(*) Show all current listening programs: `ss -plunt`

(*) Get your public IP address using Amazon: `curl checkip.amazonaws.com`
(*) Ultra fast public IP address lookup using Cloudflare's 1.1.1.1: `curl -fSs https://1.1.1.1/cdn-cgi/trace | awk -F= '/ip/ { print $2 }'`
(*) Download mp3 files linked in a RSS podcast feed: `curl http://radiofrance-podcast.net/podcast09/rss_14726.xml | grep -Eo "(http|https)://[a-zA-Z0-9./?=_%:-]*mp3" | sort -u | xargs wget`
(*) Offcloud - add a link as remote download: `curl  'https://offcloud.com/api/remote?key=XXXXXX' \   -H 'accept: application/json' \   -H 'Content-Type: application/x-www-form-urlencoded'  --data-raw "url=$MYLINK&remoteOptionId=XXXXX"`
(*) Check web server port 80 response header: `curl -I <IPaddress>`
(*) Get a list of top 1000 sites from alexa: `curl -qsSl http://s3.amazonaws.com/alexa-static/top-1m.csv.zip 2>/dev/null | zcat | grep ".de$" | head -1000 | awk -F, '{print $2}'`
(*) Get Your IP Geographic Location with curl and jq: `curl -s https://ipvigilante.com/$(curl -s https://ipinfo.io/ip) | jq '.data.latitude, .data.longitude, .data.city_name, .data.country_name'`
(*) Get current stable kernel version string from kernel.org: `curl -s https://www.kernel.org/releases.json | jq '.latest_stable.version' -r`
(*) Check every URL redirect (HTTP status codes 301/302) with curl: `curl -sLkIv --stderr - http://example.org | grep -i location: | awk {'print $3'} | sed '/^$/d'`
(*) Check every URL redirect (HTTP status codes 301/302) with curl: `curl -sLkIv --stderr - https://exemple.com | awk 'BEGIN{IGNORECASE = 1};/< location:/ {print $3}'`

(*) Download the contents of a URL to a file (named "foo" in this case): `wget https://example.com/foo`
(*) Download the contents of a URL to a file (named "bar" in this case): `wget --output-document bar https://example.com/foo`
(*) Download a single web page and all its resources with 3-second intervals between requests (scripts, stylesheets, images, etc.): `wget --page-requisites --convert-links --wait=3 https://example.com/somepage.html`
(*) Download all listed files within a directory and its sub-directories (does not download embedded page elements): `wget --mirror --no-parent https://example.com/somepath/`
(*) Limit the download speed and the number of connection retries: `wget --limit-rate=300k --tries=100 https://example.com/somepath/`
(*) Download a file from an HTTP server using Basic Auth (also works for FTP): `wget --user=username --password=password https://example.com`
(*) Continue an incomplete download: `wget --continue https://example.com`
(*) Download all URLs stored in a text file to a specific directory: `wget --directory-prefix path/to/directory --input-file URLs.txt`
(*) Download an entire website: `wget --random-wait -r -p -e robots=off -U mozilla http://www.example.com`
(*) Website recursive offline mirror with wget: `wget --mirror --convert-links --adjust-extension --page-requisites  --recursive  --no-parent  www.example.com`
(*) Download a single page saved as `wget_result.html`, implementing a custom user-agent: `wget -O wget_result.html --user-agent="Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.58 Safari/537.36" "https://ca.camelcamelcamel.com/search?sq=rk+royal+kludge"`

(*) Transfer file from local to remote host: `rsync path/to/local_file remote_host:path/to/remote_directory`
(*) Transfer file from remote host to local: `rsync remote_host:path/to/remote_file path/to/local_directory`
(*) Transfer files, recursively in archive and compressed mode, verbosely with humanly-readable (partial files ok) progress: `rsync -razvhP path/to/local_file remote_host:path/to/remote_directory`
(*) Transfer directory contents (but not the directory itself) from a remote to local: `rsync -r remote_host:path/to/remote_directory/ path/to/local_directory`
(*) Transfer a directory [r]ecursively, in [a]rchive to preserve attributes, resolving contained soft[l]inks , and ignoring already transferred files [u]nless newer: `rsync -rauL remote_host:path/to/remote_file path/to/local_directory`
(*) Transfer file over SSH and delete local files that do not exist on remote host: `rsync -e ssh --delete remote_host:path/to/remote_file path/to/local_file`
(*) Transfer file over SSH using a different port than the default and show global progress: `rsync -e 'ssh -p port' --info=progress2 remote_host:path/to/remote_file path/to/local_file`
(*) Rsync using SSH and outputing results to a text file: `rsync --delete --stats -zaAxh -e ssh /local_directory/ username@IP_of_remote:/Remote_Directory/ > /Text_file_Directory/backuplog.txt`
(*) Rsync using pem file: `rsync -e 'ssh -i /root/my.pem' -avz /mysql/db/data_summary.* ec2-1-2-4-9.compute-1.amazonaws.com:/mysql/test/`

(*) Run a http server in the current directory tree (http://localhost:8080/) : `python -m http.server 8080 && $BROWSER http://localhost:8080`
(*) Super fast port scanner: `time seq 65535 | parallel -k --joblog portscan -j9 --pipe --cat -j200% -n9000  --tagstring  '\033[30;3{=$_=++$::color%8=}m'  'nc -vz localhost $(head -n1 {})-$(tail -n1 {})'`
(*) Fast ports canner via parallel: `parallel -j200% -n1 -a textfile-with-hosts.txt nc -vz {} ::: 22`

(*) Quickly ping range of IP adresses and return only those that are online: `{ for i in {1..254}; do ping -c 1 -W 1  192.168.1.$i & done } | grep "64 bytes"`
(*) Scan all open ports without any required program: `for i in {1..65535}; do (echo < /dev/tcp/127.0.0.1/$i) &>/dev/null && printf "\n[+] Open Port at\n: \t%d\n" "$i" || printf "."; done`
```

### History